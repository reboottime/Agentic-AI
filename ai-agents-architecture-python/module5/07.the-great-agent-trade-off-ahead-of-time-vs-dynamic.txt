I want to take a moment to think about some of the different styles of execution that we've seen for agents and when we might want to use different ones. So one style of execution that we've seen from the very beginning is basically an agent gets to decide at every step what action to run. So let's just say that basically our agent at every single step is an instrumental part of the execution. That is, we go and we have a thread of execution and at every single step we're going to call out to our agent and let it look at what happened and decide what to do next. Now this has pros and cons. This is the most adaptive, right? The agent gets to look at the execution every single step and get to decide if it wants to change something, adapt something, reason about something on the fly. It's also going to be typically the slowest, the most unpredictable, and the most error prone. Why? Because every time we call the agent there's some level of randomness. It may not get it right. It's going to be the least repeatable because we may not ever get that same behavior out of that agent again. It's slower because we have to call out to the agent. It's more expensive because we're spending more tokens calling out to that agent. But it tends to be really flexible and easy to build systems a lot of time because we just give it a bunch of tools and we go say solve the task. But that's not always the right answer. There's some other answers that we've seen hinted at as well. One is that we have the agent up front go and generate essentially a workflow. Now this could be in the form of code or this could be in the form of some workflow description like or process language or something where we just go and execute it and once it gets in here the agent has no control. We may have a thousand steps executing inside there and the agent at that point is out of the loop. It's done its work up front. We execute the plan. Now what is this bias? Well once that workflow or plan whatever you want to call it down there has been generated and we start executing it, it's really fast. It tends to be predictable because once it's been created it's code or it's some workflow language or it's something that has some sort of like it looks like the programming and computing that we've done in the past. It's not some probabilistic thing where there's a random decision that's being made at every step. No, we can go and we can execute that thing pretty repeatably and predictably. The cost is lower. It's typically going to be faster. Now faster may depend on the task you're doing. Maybe there's some things that an LLM can do faster but in general it's going to be faster and it's going to cost less in terms of tokens. The downside of this is it's sort of static and fixed. It looks like our software of the past where if there's some exception or something goes wrong in the middle of here, there's no agent to see, wait a minute, things are different than expected. I'm going to adapt and do something smart here. We've lost that intelligence inside of the workflow and so that's one of the downsides of it is we can't go and sort of adapt on the fly to some problem and often this takes more work potentially to develop these workflows and get them repeatable. Positive is we can save them, we can re-execute them, we can still use an agent to generate them. If they work, we can save them, we can build test cases from them, we can do whatever and this is essentially what software engineering when we're using AI with like a copilot or something is, is it's helping us build the code or build some workflow that we're going to use. It's translating our ideas into computation through code or some other language. Now we can also do a hybrid of these. For example, we can have the agent go and generate some long workflow that it's going to go execute and then at the end give it the result and it can look at the result and if the result is wrong or indicates that some error took place, it can then go and take over and start doing that sort of step-by-step reasoning. We can do a hybrid where we have it go and say, generate a bunch of code, execute it, see if it looks right and then if there's something wrong, if it notices that something looks wrong, it can then go and sort of like, well, I'm going to try again. Maybe it generates another workflow or maybe it slows down and says, okay, well, I'm going to do this first API call and I'm going to look at the result. Now I'm going to do the second API call and I'm going to look at the result. This is more of a hybrid where it gets to initially go and try to generate that workflow, execute it, if it gets it right, it's done. But if something goes wrong, if we get that weird exception in here that manifests in the output, it then can sort of fall back to step-by-step sort of adaptive problem solving. And so there's different ways that we can go about getting there. Now this gives us the ability that if the agent can solve it up front and generate a workflow that works, then most of the time it's okay, we'll get that efficiency. Once we've gotten a workflow that we like, we can still save it. We have predictability and repeatability if the workflow works. But in the cases where it doesn't, we can fall back to it. So there's some value and some benefits to doing it in this approach. And in fact, many tools that we have do this. Like when we go and interact with a code interpreter or advanced data analysis or whatever the name of the tool is in chat.jvt right now, where it goes and writes code and executes it, it's essentially doing this, right? It's generating a bunch of Python code, it's executing it. If it works and gives us the result that we want, the right CSV file is output. It's the data analysis. It's done. It hands it back to us. If an exception gets thrown, it can go and iterate on its code and try to re-execute it. It's essentially doing a hybrid model anyways. So this can be very helpful. Now we still rely on the agent getting it all correct, being able to imagine the whole workflow. There's sort of less human involvement in this. Another way we can go about doing this is what I think of as the AI show. Now we can imagine that a human comes in at the beginning and they craft the workflow, the set of actions that are going to be run, that there's a very limited set of actions in this workflow and they're repeatable because they're related to some business process. And we don't want the agent to go and reinvent our business process. Now you can think about this with an intern, right? An intern is fully adaptive. An intern can go and do whatever you want, but that doesn't mean you just let your intern dream up their own business process. No, you may have them and say, this is the way that we do things. You're still going to be there to help execute the business process. And if something goes wrong, you're going to be there at that step to be able to identify it or be able to adapt and do things. So what we'd like to do in this case is we'd like to fix the process, but we'd like to be able to insert the AI between it is like what I think of as the AI shim. Basically where it gets to look at the output of the past step and the input to the next step and adapt the output of the prior step to be the input of the next step. That is, it gets to sit there and help control the execution in the sense that it gets to look at the output, reason about it, and decide based on what it saw, what should go into the next step, but it doesn't get to decide what the next step is. That is, for example, if we're going to schedule a meeting, first we're going to go and let's say pull the free times for the user. Then we're going to identify the correct time that works based on everybody's availability. Then we're going to craft a draft email reply. We're going to do those three things every time. Let's say we don't want the agent to get to decide to do something else. Like we don't want it to decide, okay, I'm just going to draft an email with a poll and send it back to everybody. No, we want it to do these things first every time in this sequence. With this idea, we choose the actions it's going to take, but we let it decide what data flows from the output of one action into the next one. What might it do? Well, it might go and we may get the free times, and then it may decide, well, these are the free times that are relevant to go into the next step of deciding the free times. Or it may actually decide on its own, these are the appropriate times that match the email. It can do those more reasoning related things, but we're still going to go take the next step of draft an email. It's a hybrid in that we insert it in between to be essentially an adapter that looks at the output of one step, shapes it, and then provides it as the input to the next step. I call it the shim. It's like when you have a gap between two things, that's two actions. The AI gets to fill in the gap right here by adapting the two things and making them work together. That's another process. In this one, we get repeatability in the sense that we have the same set of actions that will always be executed, but we have a little bit of unpredictability in that it will always be sort of deciding how they're put together, meaning what data flows from the output of one as the input to the next, because it'll be crafting those calls.