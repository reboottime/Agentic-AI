One of the things we know about LLMs is that when we give them time to think and we tell them to create a chain of thought, to think step-by-step, that they tend to solve problems better. Now, why is this? Well, sort of intuitively, if you think about it, if an LLM decides to do step one right, then the next logical thing, if it's been trained on a lot of data that shows it step-by-step problem solving is probably the next step. That's the next logical, you know, correct step in terms of solving the problems. And if it gets that one right, it probably gets the next step. Now, when we're doing things fully ad hoc, right, where it decides on the fly, it's not really sort of building up that complete chain of thought. It may be behind the scenes with some specialized model. It may be doing it because it's spelling out and explaining its actions, but often it can be really effective if we have it think about plans up front. So one of the simplest things we can do often to improve the reasoning of our agents is we can have them go and plan at the start. So we want it to go and think about its plan, build a complete plan of the steps that it's going to take before it actually does anything. Before it goes and starts executing actions, using the different tools at its disposal, and taking action, we want it to think in advance, step-by-step, about what it's going to do. And at the beginning of a conversation, build a plan. So let's say that we go and we build one of these plans. Well, there's many different ways that we can then go in and use the plan. Now let's talk about what those are. So let's assume that we've built a plan and we have our plan over here that it's built out. One thing we could do is we could have the plan be some fixed execution that we go and we just basically lightning bolt this plan where we have it go and run the plan. So we just go and run it. Now, what would this look like? Well, if it goes and creates a plan, it could create and manifest the plan in code. And code is basically a full plan of what's going to be done step-by-step. So it can spell out and explain step-by-step what it's going to do. It can manifest it in code, and then we just go and execute the plan. And the LLM is not involved in the plan at all. It's just involved in the creation of it upfront, manifesting it in code, and then we go and execute the code and get the result back. Now, that's sort of fully planning upfront and it's executing it all outside of the agent's control. Now, why might we want to go and do this? For example, why would we want to go and take a plan and turn it into code? Or we might turn this into some business process or workflow language. There's many things that we could do, but we could go and essentially turn this into something that we can go and execute like a workflow or some code. Why would we want to do that? Well, one is we get repeatability, right? If we go and we create code and we execute this code and it was right, we can save that code and we can re-execute it many different times with the same inputs. If we know our sort of structure of our inputs is going to be the same, we can put that code aside and we can execute it over and over. Now, this is what we do in software development all the time is we have the agent essentially generate code and then we go and save that code somewhere like in a repository. And then later we go and we load it into memory and we run that code. You know, we lightning bolt it and run it over here. I'm sorry for my terrible lightning bolt, I'm falling apart on my iPad. So we could go and do something like that where we have it go and generate the code, we can save it, we can reuse it, we can use it in other projects, but that's fully planned upfront. Another thing it can do is it can plan upfront and then we can have it go and put that as a memory into the LOM. So we put that in as a memory, we say, hey, this is what you're supposed to do, like follow your plan. And then it goes and does its ad hoc step-by-step execution of actions. Now, the advantage this gives us is that it's still getting to think step-by-step upfront, it can remember its plan and then see it, but it can still go and execute actions one at a time and it can adapt in between. If it goes and it writes code and we execute that code and there's some mistake at some point and some step, the LLM's not injected in the code anymore, right? And it can't see the result of individual steps, it just says, hey, the code failed, maybe we give it a stack trace so it can see where it failed, hopefully, but it's not there dynamically saying, oh, wait a minute, this is different than I thought, I'm gonna adapt the code. No, it gives us the code, we execute it, and if the code has a mistake, we can't go and adapt. So one thing we can do is we can go and have it plan in advance, put that plan in as a memory, and then it can go and execute sort of ad hoc, but it still has done sort of that chain of thought where it remembers what its plan was, but then it goes and executes on the fly, and if something unexpected happens, it can adapt, but within the context of the plan that it generated before. So this can be a really powerful and effective, simple way of planning, simply have the LLM go and think about the plan, think step-by-step how to solve the problem upfront before it starts executing the individual actions. The other thing that's really important about this is if we think about this upfront planning, let's say this upfront plan creation is a tool that it can call out to, and we force it to use this tool at the start of every execution, is this means that we can separate that planning piece, which is so critical, and we can use a better model. We can use a more expensive, slower model to go and generate the initial plan that it should follow, and this can help the reasoning. So we don't have to go and have a really high-quality, expensive model at every step sometimes. If we just go and have a really high-quality model, think about the plan upfront, and then have a lower-quality model try to follow the plan that was generated by a higher-quality model. So going and just doing this simple thing of let's generate a plan, and then let's put it in as a memory, and then let it execute it step-by-step can be a really effective thing to help agents perform better.