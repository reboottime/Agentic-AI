To build really powerful agents, you need to think about generative AI itself and prompts as a new form of computation. We don't want to think of them as some neat trick that we do in chat, we want to think of them as fundamental computational building blocks that we can use. I want you to think about generative AI and prompts as operations that you can have this new generative AI CPU perform on your behalf to do really powerful things. Now, in fact, it's prompts that separate amazing agents from agents that are just doing the things that we already do. I want to give you some examples. I want you to start thinking of prompts themselves as computation because when you start thinking of prompts as computation, that means you can start building tools for your agent that are based on prompts that you create. So you can empower your agent with all kinds of incredible abilities simply by giving it tools that essentially prompt the LLM. Let's start off with something apparently really simple. Generate a random list of file names with full pass. Let's imagine what might be in someone's downloads directory. I have it do this and it comes back with this random list of file names that could be in a downloads directory. Now, let's stop and pause for a minute on this. Let's think for a moment. If I told you go and write a Python function to fake a downloads directory convincingly and generate a random set of file names, I want to challenge you to write one that produces output as realistic as this one is. Now, notice I'm doing this in a chat interface, so it knows some about me from memory, so it's inserted my name into it. But you can look at all the different things that it's got, like it's dreamed up coding project, MySQL database thing, taxes, the installer for game, because I've been chatting with it about game and doing the simulations of the game agents. The resume, meeting notes, it generated all of this correct file types. What did I do to get there? I gave it a prompt. Now, imagine you were doing testing and you needed synthetic data, right? That is doing synthetic generation of data on steroids. All it is is a prompt, but it is a computation. It's a computation now I could reuse over and over. If I wanted to generate fake file paths for testing and feed that in or fake names or whatever, I've got a computation that can do it. Now, let's take that computation further. What is something that we think of as computation all the time? Organization of data or sorting of data. Well, let's put that on steroids, and let's take this list of fake files, and I took it into another chat session, and I put it into a prompt. I just said, please organize these files for me into a directory hierarchy based on file type. Then I dumped into the prompt all the files, and it's obviously chopped off here on this prompt. Now, what does it do? It comes back with the organized directory hierarchy for all this stuff. That is computation. It is organization of the files. It has dreamed up the directory structure. It is semantically looked at the files and the types, and sorted it all, and pieced it into a directory structure. But it wasn't one that required me to go write a ton of code to look at the ending file path, and then try to decide what to do with it. No, we just did it automatically. Now, this one, I could probably write something in code to do this. Although, it's not going to be as flexible because if I just added a new file type to the input to this thing, the operation will automatically account for it. I don't have to go and teach it new types of files because it already has them baked in. This is one of the real key capabilities is the underlying prompts themselves are tapping into operations, it already knows, and information it already knows about, that's built into this generative AI CPU. If I went and I added a new file type, I don't know what it would be, but let's say I added SVG, Scalable Vector Graphics. It's not going to have to be told what SVG is, it's already going to know what to do. If I go and add it in and I've written all this in code, my code is not going to be flexible enough to automatically know what to do with SVG. That's one of the key things is these are really powerful operations, but they're powerful operations that are very, very extensible and maintainable and do interesting things. But let's go and make it more powerful. Doing it based on file extension is like what we can already do today. But I said, and I just followed up and I said, reorganize them into a hierarchy based on work slash personal activities. It goes through and reorganizes all the files based on that semantics of what I'm trying to do. Good luck trying to implement this in code. Write code to do that. It's going to be extraordinarily difficult. Why? Because it depends on what the files are. You're going to have to figure out what are the right categories and it requires knowledge and understanding of some form of what it is, what those files represent based on the names and what work, and personal means, and how you might want to organize them. It goes through and it automatically figures it out. We've got career and professional development, research and AI, meeting notes. Try to do code, create your own code to do that. Extraordinarily difficult. This prompt now is a computation and we can empower our agent with a tool that does that computation based on that prompt. Suddenly, we have a really powerful agent. We have an agent that we want it to reorganize our files in a particular way. We give it a tool that does file reorganization and it's based on a prompt. Now, I want you to expand your mind though a little bit more about how powerful this concept is. I want to go back and think about all the policies and documents that we have, where we teach human beings to do things. We explain the rules or the processes for doing things. All of those documents are essentially sets of instructions that we can essentially plug into our new generative AI CPU as part of a prompt. What I've done here is I've taken the Vanderbilt travel and business expense policy, 17-page PDF. I've taken a rental car receipt and I tell it some things for privacy because it's my personal rental car receipt. As I don't list any names or dates, read and understand the travel policy. Then think step-by-step, does this receipt comply with the travel policy? It comes through and it had a whole list of things that were correct, and then it points out issues on this rental car receipt, which makes sense because I was traveling for personal, but I'm just auditing it. Would this personal expense actually meet Vanderbilt's travel policy? The answer is no, it wouldn't. One of the key reasons, if you look here at insurance, for example, is Vanderbilt already has rental car insurance. You're not supposed to buy it when you get a rental car. But I don't have rental car insurance, so I bought the collision damage waiver insurance, and it's saying, hey, this would be non-reimbursable. If you think about that, I've turned a policy into a computation, apply policy. But you can also think about it as we build agents, part of the core computation can be taking a policy that already exists, it's human understandable, and having the agent read it and apply it to something. It also can make it so that we can build agents that have tools that are really easy for other human beings to understand. We can say at this point, the agent is going to use a tool where it's going to apply that policy to this expense, to this invoice, to whatever it is. Suddenly, the code for what that thing is is separated out. We say that whatever the current version of the policy is, that's what it's going to apply, just like a human would be. But now that is a tool, that is a step in the computation. It is a new capability that we have that we can bake into our agent. So if we're going to build really powerful agents, we have to start thinking about how do we use this new generative AI CPU to build computations that are based on promise.