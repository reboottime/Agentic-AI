One of the really important roles that prompts can serve in terms of their ability to perform computation is to help bridge an important gap for us. And it's a gap that is critical with agents. Now, agents already themselves know how to do this, and we've probably seen them doing it already, but I want to talk about it sort of more precisely in detail so we can see what we're talking about here. Now, when we're working with computer systems, we're always struggling with this fundamental problem we have. We have the real world that people live in and the systems and machines and all the things out there in the world, and they produce messy information. It's unstructured. We have all this human text, all the news, all kinds of things that we tell each other, record in meetings. It's free-flowing. It's analog. It's full of exceptions. But we need to go and we need to marry that together with our traditional computation, our APIs. But our APIs take really specific information. And most of the time, as developers, we require them to take really specific information, and they cannot handle the edge cases, and the format has to be perfect. And it creates this gap. How do we bridge the real world with this sort of highly structured world that we have of our APIs and our traditional computing system? This is something that prompts as computation are extraordinarily effective with. Now, the idea behind this is we're going to take all of that information, and then we use prompts to get it into the structure that we need to interface with our real world computing systems. And our agents do this implicitly when we are going and having them call tools and structuring the information. But we can also do this more directly and more thoughtfully if we want to empower agents with tools to take data in one form and convert it to the form that the agent is going to need to use to call tools. And sometimes taking it out and having it as a separate tool to do the conversion can be really powerful. So let's start off with a really simple example. Create a step-by-step plan to bake a cake. And we get a cake. Now, what's the problem with this? Well, let's imagine that we have an agent and we want it to go and use this plan to bake the cake. And we want it to iterate through the steps in the plan. Or let's imagine we want to go and feed this into some existing, you know, Python infrastructure or Java infrastructure, whatever programming language you're wanting. We want it to loop over the steps and do something with the steps. Well, now we've got a problem, right? Because this is a plan, it clearly has sort of structure from the perspective of an agent or a human, but it doesn't have structure that our computing systems can understand. I can't write a for loop over these steps because it's just not in the right shape and form. So let's fix that with a prompt. Convert the steps into JSON in the following format. And I simply give it the format to do that conversion. It says, okay, here's the step-by-step cake baking process. And it converts all those steps into JSON in the format. Now I can feed that into a traditional program and I can run a for loop over it. I can do stuff with it. I can analyze it. I can send it to APIs. I can do whatever I need to do with it. And so that prompt is serving as the bridge to take that unstructured information and give it structure. Really powerful capability. Now let's go and look at something that isn't just it generating information and then reshaping its own information. This is the Vanderbilt homepage today. It's got a lot of interesting things, including Amplify, which is our generative AI open source enterprise platform that we've built out. And my team created and helps maintain. And it's got all these news stories related. What if I want to turn that into JSON? What do I do? Well, I turn it into a prompt. I've copied and pasted all of the information from the homepage today. And I said convert this content into JSON in the following format. I give it the format that I want. I dumped all that content in there. I didn't do anything to filter it. You know, it's got all the messy sort of formatting from highlighting and copying and pasting everything. And now I've got it out in a structured format. Now I could feed that into a tool. I could turn it into an RSS feed. I could do whatever I want to do with it. I could have my app display news headlines. Whatever I want now, I can take and I've gone from that messy, real-world information, and I've turned it into structured data that I can do something with. I can send to an API. I can iterate on in a for loop. I can do whatever I need to do. So it's serving as that bridge. Let's look at another example. We don't have to think just in terms of text. We can think in terms of all kinds of documents, receipts. We've already seen the example of auditing a receipt because it's extraordinarily good at extracting information. But I can also take things like images, screenshots. I could take a picture of a hospital room. Is the patient in the room? Is the nurse in the room? Is the family in the room? And suddenly you see the power of this, the ability to extract structured information. Give me an inventory of what's in the room. You know, is X in the room? Is Y in the room? Yes or no? And extract it in a structured way that can then trigger and deal with our existing computational systems. Let's do something simpler here. Here's a screenshot of a part of the Vanderbilt homepage. Convert this into JSON in that same format. And now we have a list of headlines extracted from what it can see in the image. So prompts are computation, but they can also be a powerful bridge between the unstructured sort of messy world of information in the real world that our agents will want to interact with to be really powerful. And the sort of highly structured world of our traditional computing systems and APIs. And so when we build tools that are based on prompts, one of the just really powerful operations that we can form is build prompt-based tools that extract structured information from things from the real world or things that the AI agent generates. Maybe we have it think of its plan in natural language first and then convert it to JSON in the second step. Now sometimes I actually find this is really powerful and important because if you think about it, if I tell you to write a plan and you just write it in natural language, I think of it as cognitively easier than to write a plan in JSON, for example. And now I don't know if there's scientific proof behind this, but my intuition is that doing it in multiple steps can often be better.