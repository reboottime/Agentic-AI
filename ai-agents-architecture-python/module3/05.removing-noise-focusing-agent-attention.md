# Removing Noise: Focusing Agent Attention

## Core Problem: Token Asymmetry

LLMs have different limits for input vs output tokens:

- **Input capacity**: Large (can process many tokens)
- **Output capacity**: Limited (fewer tokens can be generated)
- **Cost asymmetry**: Output tokens more expensive than input tokens

## Memory vs Message Size Constraints

### The Limitation

```
Memory (Large) → Task Description (Limited) → Agent
```

- Memory can contain extensive information
- Task descriptions limited by output token constraints
- Agent may lack sufficient context for quality work

## Solution: Intelligent Memory Selection

### Pattern: ID-Based Memory Selection

Instead of outputting full memory content, output memory identifiers.

#### Step 1: Memory Analysis

```
Agent analyzes memory: [Message1, Message2, Message3, Message4, Message5]
```

#### Step 2: ID Selection

```
Agent outputs: [1, 3, 4] (relevant message IDs)
```

#### Step 3: Memory Inflation

```
System inflates IDs → Full content of Messages 1, 3, 4 → Task description
```

## Benefits of ID-Based Selection

### Token Efficiency

- **Output**: Short list of IDs vs. full memory content
- **Input to next agent**: Full context through programmatic inflation
- Overcomes input/output token asymmetry

### Accuracy Protection

- Agent cannot corrupt memory content (only references existing data)
- Prevents hallucination of facts
- Maintains data integrity from API calls or previous results

### Scalability

- Handles large memory volumes efficiently
- Enables rich context transfer without token limits
- Allows expert selection of relevant information

## Advanced Pattern: Expert Memory Selectors

### Specialized Selection Agents

Create dedicated agents for memory curation:

```
Coordinator → Memory Selector → Relevant IDs → Task Agent
```

### Benefits

- **Specialization**: Expert prompts for memory relevance
- **Burden relief**: Main agent focuses on core tasks
- **Tool integration**: Memory selection as reusable tool

## Implementation Strategy

### Tool Design

```python
select_relevant_memories(task_description, memory_ids) → [selected_ids]
```

### Workflow

1. Agent identifies need for specialist help
2. Calls memory selection tool with task context
3. Receives curated list of relevant memory IDs
4. System inflates IDs to full content
5. Passes enriched context to specialist agent

## Key Advantages

### Context Preservation

- Rich information transfer without size limits
- Full context available to receiving agent
- No information loss in handoffs

### System Efficiency

- Minimal output token usage
- Maximum input utilization
- Cost-effective context sharing

### Data Integrity

- No memory corruption through summarization
- Factual accuracy maintained
- Reference-only approach prevents hallucination

## Design Principle

Separate memory selection (what to include) from memory content (actual information) to overcome token limitations while maintaining context richness.
