I want you to imagine that you're working with an intern and you're gonna delegate a task to that intern. Now, when you start thinking about it, there's lots of different ways that you could have that communication between you and the intern. Lots of ways you could go about solving that coordination problem. And what it turns out is just like in the human world, there's all kinds of ways of communicating and coordinating with that intern. There's all kinds of ways that agents can coordinate with each other. And a lot of it deals with the sharing of information. And so let's take a look at this. So let's imagine that I am the boss and I go and I delegate some task to my intern. So we'll just call this the task. The intern goes and does some work on my behalf. They go and do whatever work they're gonna do over here. And then they come and they pass back, let's say a section in a report. So let's imagine that I'm trying to write a report and I know this intern can go and write one of the sections. So I go and delegate that task to the intern. I say, go and write this section. And they go and do a bunch of work and then they hand me back the section and I put it into the report. This is one style of communication. And we can think of this, this is essentially message passing. So when we go and we describe the task and we pass it to the intern, that is a message. And then the intern goes and does a bunch of work. And when they're done, they pass us a message back with the result of that work, the section. This is one of the simplest forms of agent communication, just like it's one of the simplest forms of working with human beings. Now, what's really, really important when we go and we're doing message passing is that we have a really good description of that task. If we're gonna go and hand this work off to our intern, the intern's ability to perform the task is gonna be based on how good of a set of requirements we give them for that task. If we do a really good job of describing what they need to do, then they will often end up doing a good job in the actual task itself. If we fail to mention some important information, then the intern may not do a good job. So message passing is a really simple thing, but it relies on us going and having a really good description of a task. Now, if you think about this, what this means with an agent, when we are going and having one agent handing off to another agent, basically what the first agent is doing is using a handoff tool or a call agent tool to say, go and give this task to this other agent. So it becomes very important that the first agent knows how to write a rich and very good task description in that message that it's sending to the second agent. In fact, the quality of what happens is directly dependent upon the quality of that task description. So if our agent goes and looks at this tool and it says, oh, I'm filling in a JSON attribute. JSON attributes are short. I'm gonna write a really short task description for the agent. What we'll see is this other agent over here gets a message that lacks sufficient context for it to go and do a good job with the task. And so one of the things when we're message passing, and particularly when we're using agents that use tools to call other agents and pass the messages, is we have to make sure that our agents do a really good job on the descriptions of those tasks and the information that they give, the context that they provide. Because one agent is basically gonna be handing off a task with complete context in the message to the other agent, and we wanna make sure it's sufficient. Now, sometimes it's not always clear that the first agent knows what information is needed. For example, let's imagine that you go off and rather than hiring an intern, you hire some expert to perform some action for you, to go and do some work for you. You may not know what are the inputs, what is the important information that that expert needs in order to do their work. And so this creates a challenge when we're doing task-based. If we have one really specialized agent that knows a lot about this, and then whenever it arrives in a situation where it needs to call out to that expert, it sends it a message, it may not know what to put into that message. It may not capture the context appropriately. So another way that we can go and do this is let's imagine that as the boss, I have this stream of work that I'm going and performing. Now I'm doing a bunch of tasks, I'm gathering all kinds of other sections, I'm gathering inputs from other people along the way. One way that I could go and bring that expert in is I could create a log of all the information I've gathered so far, the draft report, all the inputs I've received from everybody. And then I could go and I could call the other agent or intern or expert and give them the entire log. And they could go and look at everything that's been collected so far, and then produce a result that also gets added onto the log. So they go and produce a result and add it back into the log. Now, the advantage of this is that the expert can look back into the history and can decide what is the relevant context to perform their task. What it does is it alleviates this first agent over here, the one that's doing the coordination, the boss, of having to know what context to pass off and how to write a really good task description. It can just say at this point, I need to call this other agent. Now we can actually enable this with agents if we think about the stream of work is the conversation or our memory of all the actions we've taken and the results of all those actions. If we're capturing a memory, what we can do is a handoff where essentially we hand off that memory to the other agent. It does its work with that memory, and then it adds back at the end some new result. And this is one way where it basically can go and take in the memory, do some work, and then add one additional item to it. Now, this is great when we want it to be able to pick its own context. Now, this is great, but sometimes we would like to do a little more rather than just get back the result. Sometimes what we'd like to do is actually be able to check the work or see the work, because maybe that expert went and discovered some things along the way that are valuable to me that maybe I want to incorporate, but in a different way. So maybe it's work that the expert did, but I can also use that work. So let's imagine that you were the boss, you were coordinating this work stream, and you're getting all these different inputs into the work stream. And then at some point you go and you basically hand off the work stream to this other expert, and they go and add a bunch of stuff to it as well. They're getting all these different inputs. And then basically what we do is hand back off to the boss. But what we do is we maintain a cohesive memory across both of them. So when we hand off to the other expert, not only can it see the full memory, but it can add all of its intermediate steps to that memory and then hand back off. So we can do a handoff where we go and hand off so that the other agent gets the full context of everything that's happened in the past. And it just provides one update at the end, which is the end result. Or we can actually hand the entire memory off to it, let it go and iterate. And this is a fully shared memory model where they go and it iterates, sees all the memory, iterates on it, it adds its own memories to it, and then hands back the complete log or work stream to the first agent. Now, this has benefits to it. And we have to think very carefully about which one we go with. Now, the benefit to handing off the memory to the second agent is it can go and look at the full context and hopefully get rich information it needs to make a decision. The downside is it's going to be exposed to all types of things that happened in the past that may not be relevant to it. So when we do this, we have sort of some of the complexity that we have that led us to think about breaking up into a multi-agent system in the beginning, which is we wanted to isolate and limit the complexity that any individual agent had to deal with. When we start handing off the whole memory, it's not as clean as the task anymore before. We could just hand off the task, and then it could go and performance work. And that made things a little bit easier for the agent. Now, the downside was we had to get a really good task description. So we can go and account for that by handing off the entire memory. But the challenge with this is now this other agent has the added complexity. If it's going to be seeing things in the history and in the memory, that maybe it doesn't need to do its work and maybe add additional complexity. Similarly, if we hand off not just a result, but the entire work stream of the second agent, basically take its entire set of memories and merge them back in, we may expose the boss agent to complexities that it does not need to see. Like all the results of checking different people's calendars for free times are probably not things that the boss agent needs to know. It just needs to know, did the meeting get scheduled or not? Now, maybe the scheduling agent does need to see the entire memory because it needs to know who all was involved in the work stream and all the different email addresses and all the different inputs that are going into that meeting and estimates of time. Maybe there's a whole bunch of reasons it does need to see it. But we have to think through this. And this is one of the complexities. We have to understand that how we go and coordinate the agents. Do we pass messages? Do we hand off memories? But all of this influences what context is available to the second agent and then what context comes back to the first agent. And all of those things dramatically affect the reasoning and the prompting of these things.