I want you to imagine you've just hired a brand new intern at your company. What is the guaranteed way to make sure that they fail at a task? The basic answer is you give them terrible instructions on what to do. And the prompt is the instructions for our agent. So if we don't give our agent a great prompt to run that loop, we're going to end up setting it up to fail. So we have to think carefully about what goes into that prompt, how do we structure it? And there's so much, and often it gets approached as just like, it's a big wall of text. Just go add more text to it until it works. But I want you to kind of break this down and sort of think about it in a slightly more structured way. How do we go about and construct this prompt? So I want to give you a basic mental framework to think about. You can think of it as GAIL, basically goals or instructions, what you want your intern to do and how, the actions that your intern can take, things that they can do in the office like send an email or go down to a particular department and get some accounting code, whatever it is, the actions that that intern can take, information that the intern needs to go and complete this particular task. So you're going to have things that are independent of task, right? Things that you always want the intern to do, guidelines to follow, rules for your organization. You know, there's a bounded set of actions maybe that that intern is allowed to take. And then you're going to also tell them about language, how to communicate with you, how to describe the results. Like the output should always be a TPS report. The output should always be in this format so that I can, you know, you know, respond to you appropriately. You're going to give them some rules about how to communicate with you. Now I want to break this down a little bit and talk about this. I know this is overwhelming to look at, but once you start getting into the details of it, you'll see that this framework can help you to think through it. What are the goals and instructions? Things that you want them to do, be helpful, take on this particular persona. You want the agent to always respond in sort of a customer service centric manner, rules, things that can and cannot do, process. This is going to be a really important one. First, you should always go and check the list of expenses that are already entered into the system. Then you should determine if the expense has already been entered. And if it has, you should ask the user if they want to add it anyways. Process is things that are sort of process steps that should always be followed. Just like you might teach an intern, you'd say, you know, you're not just going to go in and say, go and enter this expense. And then you see, oh man, they're entering duplicates. You'd go back and say, well, here's the process. First, we always check if there's already one there. So goals, instructions, this is where we get to define its behavior. We get to tell it things that it should always do and in what order, that type of stuff. Sort of the road rules, actions. These are things that the intern can do or an agent can do. These are the ways that it can interact with the computer system or its environment. The actions it can take. Information, so this could be the feedback from the actions that it takes. This could be documents that are needed to complete the task. This could be whatever it is, but this is something that is typically ephemeral. It's something that's related to the current task that it's working on. It may be transit, sort of temporary, like we're going to capture the feedback from executing a particular API call and we're going to provide that back as information. That's all the information. The things that it gets as input at the beginning and then sort of our ongoing sort of session state as we're going and completing the action. This is information that it needs to decide the next action. Initially, when it's deciding the next action to take, it's just getting whatever information we input in. And then over time, as it executes actions, the information is going to accumulate things like the result of other actions that have taken place or updates to the system or whatever it is. And then finally, the language, how we want it to communicate with us. Now we've talked about this, about how to structure outputs, and that's where the language comes in. As we're trying to tell it how to communicate with us. Now we can do some really amazing things with language later, and we're going to talk about those, but language can be a really important piece as well. So let's take a look at this in an agent prompt. So here is our agent prompt. I'm going to take one second, read it to you. You are action agent, a helpful AI assistant. This is our persona. We're telling it who it is. Your goal is to accomplish the task given by the user. So this is what it's supposed to do. If you have enough information to directly respond to the user's request, you should do so. If you need to complete tasks, you can use the provided tools to help you. Whenever you're completely done with the task, you should tell the user the result and terminate the conversation. The available tools are, and you would have a list of tools, but I'm leaving it out here and just putting in dots so that I can get this prompt under one slide. Always respond in the following format. And then I have stop and think step-by-step, insert a rich description of your thoughts there, and then some action format. And this action format is similar to what we did in the past where we were looking at sort of the raw prompt engineering structure that we could use to get it to output actions. Now if we think about in terms of this GAIL framework, this is the G, the A, and the L. There is no I necessarily in here. We have goals slash instructions. We're telling it its persona. We're telling it the goal. We're telling it process that it should follow. We're giving it a set of tools or actions that it can take. And then we're telling it the language to communicate with us in. And so we're building up a structure for an agent prompt. Now when we go and we start thinking about building a prompt, a prompt is going to be broken down into a series of messages, and messages have different roles. And typically what we're going to do is we're going to tell it the G, A, and L part as system messages. These are like ground rules, things you're always supposed to do. And we're going to give it information like feedback on what's happening or inputs to the system as user messages. So those are going to be the key things. Now inside the prompt, we're also going to have typically the assistance decisions, what it chose to do, but I'm not representing that in here. So when we go off and we begin building these prompts, these are the core things we're going to be doing. We're going to be telling it goals and instructions on how to accomplish tasks. We'll be giving it a list of actions that it can take or tools it can use. We'll give it information that it needs in order to select which action or tool to use. And then we're going to have language that defines how to communicate back with us. And we can use function calling to make this language sometimes simpler, but we're still going to have language in this whole thing that helps us decide what it's asking us to do and how, and we can do all kinds of interesting tricks there. So these are sort of the core things that we're going to use and build upon.