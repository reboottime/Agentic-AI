# Understanding Feedback & Memory

Q:
> write a 2-3 paragraph discussion of how AI Agent memory works and why the results of API or tool calls are represented as "user" messages.

A:

AI agents use LLMs as reasoning engines, but LLMs have fixed parameters after training, meaning they cannot store new information internally once is trained. To maintain memory across interactions, agents use external storage systems that preserve conversation history and context outside the model. Each time the agent processes a request, it retrieves this stored memory and provides the complete conversation history to the LLM as input context.

API and tool call results are represented as "user" messages because they provide external information to the agent, just like human input. From the LLM's perspective, both API responses and user messages are new data that must be processed and incorporated into its reasoning.
